{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"colab":{"name":"Deep_Classifier_Trainer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_ZiiWE7hajW-"},"source":["runLocation = \"googlecolab\" ## local googlecolab\n","\n","# %%\n","if runLocation==\"googlecolab\":\n","    from google.colab import drive\n","    drive.mount('/gdrive')\n","    %cd /gdrive/My\\ Drive/Deep\\ Classifier\\ Trainer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHYN1UdGdN2P"},"source":["### Imports\n","\n","import numpy as np\n","import cv2 as cv\n","import random\n","import pickle\n","import glob\n","import os\n","import shutil\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout,AveragePooling2D, Flatten\n","from sklearn.model_selection import train_test_split\n","# from tensorflow.compat.v1 import ConfigProto\n","# from tensorflow.compat.v1 import InteractiveSession\n","!pip install livelossplot\n","from livelossplot.keras import PlotLossesCallback\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","# config = ConfigProto()\n","# config.gpu_options.allow_growth = True\n","# session = InteractiveSession(config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJx3traJZxek"},"source":["### ALL FUNCTIONS ###\n","\n","\n","def splitDataset(): ## Split Files for Testing\n","    traindatafolder = dataPath\n","    testSplit = test_split_size\n","    \n","    ## Make Test Folder if Not Existing\n","    if not os.path.isdir(traindatafolder[:-1] + \"test\"):\n","        os.mkdir(traindatafolder[:-1] + \"test\")\n","    else:\n","        print(\"Test Folder Existing! Split will add to existing test dataset. Press ENTER to continue...\")\n","        input(\"\")\n","\n","            \n","    ## Iterate Per Class\n","    \n","\n","    for ctrPath,classPath in enumerate(os.walk(traindatafolder)):\n","        if ctrPath==0: continue\n","        thisClassPath = classPath[0]\n","        thisClass = thisClassPath[len(traindatafolder):]\n","\n","\n","        ## Create Class Folder if Not Yet Exist\n","        if not os.path.isdir(traindatafolder[:-1] + \"test/\" + thisClass):\n","            os.mkdir(traindatafolder[:-1] + \"test/\" + thisClass)\n","    \n","    \n","        ## Split For Validation\n","        \n","        imgFiles = []\n","        for ctrext in range(0,len(ext)):\n","            imgFiles.extend(glob.glob(traindatafolder + thisClass + \"/*\" + ext[ctrext]))\n","\n","        \n","        fileSelectIn = [x for x in range(0,len(imgFiles))]\n","        tmp = [x for x in range(0,len(imgFiles))]\n","\n","        fileTrain, fileTest, _ , _ = train_test_split(fileSelectIn,tmp,test_size=testSplit)\n","        \n","\n","        for f in fileTest:\n","            filename = imgFiles[f][len(traindatafolder+thisClass+\"/\"):-len(ext[0])]\n","\n","            for ctrext in range(0,len(ext)):\n","                try:\n","                    shutil.move(traindatafolder + thisClass + \"/\" + filename + ext[ctrext],traindatafolder[:-1] + \"test/\" + thisClass + \"/\" + filename + ext[ctrext].lower())\n","                except:\n","                    pass \n","                    # print(\"Move error: \")\n","        \n"," \n","    print(\"Finished Splitting.\")\n","\n","\n","\n","def trainModel():\n","    #from tensorflow.keras.preprocessing import image\n","    if selectedModel == \"vgg16\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.vgg16 import preprocess_input\n","        sourceModel = keras.applications.VGG16\n","    elif selectedModel == \"inceptionv3\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_v3 import preprocess_input\n","        sourceModel = keras.applications.InceptionV3\n","    elif selectedModel == \"inceptionv2\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"resnet50\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.resnet50 import preprocess_input\n","        sourceModel = keras.applications.ResNet50\n","    elif selectedModel == \"mobilenetv2\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","        sourceModel = keras.applications.MobileNetV2\n","    elif selectedModel == \"inceptionresnetv2\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"mobilenet\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.mobilenet import preprocess_input\n","        sourceModel = keras.applications.MobileNet\n","    elif selectedModel == \"xception\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.xception import preprocess_input\n","        sourceModel = keras.applications.Xception\n","\n","        \n","    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","    from tensorflow.keras.models import Model\n","    from tensorflow.keras import optimizers\n","    from tensorflow.keras.callbacks import EarlyStopping\n","\n","\n","    # Adam is an optimization algorithm, replacing the very old Gradient Descent.\n","\n","\n","    modelName = 'model_' + selectedModel;\n","\n","\n","    #imports the model and discards the classification layer.\n","    base_model=sourceModel(weights='imagenet', \\\n","                              include_top=False, \\\n","                              input_shape = (imgsz,imgsz,3)); \n","\n","\n","    #Show Architecture\n","    for i,layer in enumerate(base_model.layers):\n","        print(i,layer.name,layer.trainable)\n","        \n","\n","    ## To Check Last Layer\n","    #base_model.layers[-1]\n","\n","\n","    x=base_model.output\n","\n","    addedLayers = 0;\n","    # if selectedModel == \"vgg16\":\n","\n","    x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n","    for neuron in neurons:\n","      if neuron<1:\n","        x=Dropout(neuron)(x)\n","      else:\n","        x=Dense(neuron,activation='relu')(x) \n","      addedLayers = addedLayers + 1\n","    \n","    preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n","\n","    # elif selectedModel == \"inceptionv3\":\n","    #     x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n","    #     preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n","    # elif selectedModel == \"resnet50\":  \n","    #     x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n","    #     preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n","    # elif selectedModel == \"mobilenetv2\":  \n","    #     x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n","    #     preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n","        \n","\n","\n","    model=Model(inputs=base_model.input,outputs=preds)\n","\n","                      \n","                  \n","    for layer in model.layers[0:-(addedLayers+layersToUnfreeze)]:\n","        layer.trainable = False\n","\n","    #Show Architecture\n","    for i,layer in enumerate(model.layers):\n","        print(i,layer.name,layer.trainable)\n","\n","        \n","    ## This datagen is used only for viewing, prior to preprocessing\n","    viewing_datagent=ImageDataGenerator(rotation_range=rotAngle,\n","                                    horizontal_flip=flipHorizontal,\n","                                    vertical_flip=flipVertical,\n","                                    validation_split=validation_split_size)\n","\n","    ## Official Training Datagen, PreProcessed\n","    if rotAngle == 0:\n","        train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                        horizontal_flip=flipHorizontal,\n","                                        vertical_flip=flipVertical,\n","                                        validation_split=validation_split_size) \n","    else:\n","        train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                        rotation_range=rotAngle,\n","                                        horizontal_flip=flipHorizontal,\n","                                        vertical_flip=flipVertical,\n","                                        validation_split=validation_split_size) \n","\n","    print(\"Training Dataset:\");\n","    train_generator=train_datagen.flow_from_directory(dataPath,\n","                                                    target_size=(imgsz,imgsz),\n","                                                    color_mode='rgb',\n","                                                    batch_size=batchSize,\n","                                                    class_mode='categorical',\n","                                                    shuffle=True,\n","                                                    subset='training');\n","\n","    print(\"Test Validation Dataset:\");\n","    validation_generator=train_datagen.flow_from_directory(dataPath,\n","                                                    target_size=(imgsz,imgsz),\n","                                                    color_mode='rgb',\n","                                                    batch_size=batchSize,\n","                                                    class_mode='categorical',\n","                                                    subset='validation',\n","                                                    shuffle=True);\n","\n","    print(\"Sample Viewing Dataset:\");\n","    ## Only for Viewing Unprocessed Images\n","    view_generator=viewing_datagent.flow_from_directory(dataPath,\n","                                                    target_size=(imgsz,imgsz),\n","                                                    color_mode='rgb',\n","                                                    batch_size=batchSize,\n","                                                    class_mode='categorical',\n","                                                    shuffle=True);\n","\n","    ## Show 5 Sample Images\n","    x,y = view_generator.next()\n","    for i in range(0,min([batchSize,5])):\n","        img = x[i]\n","        plt.imshow(img.astype(np.uint8))\n","        plt.show()\n","        \n","                                                      \n","\n","\n","    adamOpt = optimizers.Adam(lr=learningRate);\n","    model.compile(optimizer=adamOpt, \\\n","                  loss='categorical_crossentropy', \\\n","                  metrics=['accuracy'])\n","    # Adam optimizer\n","    # loss function will be categorical cross entropy\n","    # evaluation metric will be validation accuracy\n","\n","    if useAllSamples:\n","        step_size_train=train_generator.n//train_generator.batch_size\n","    else:\n","        step_size_train=fixedStepSize\n","\n","    if enableEarlyStop:\n","        es = EarlyStopping(monitor=estype,mode='auto', patience=patience)\n","        \n","        history = model.fit_generator(generator=train_generator,\n","                            validation_data = validation_generator,\n","                          steps_per_epoch=step_size_train,\n","                          epochs=maxEpochs,\n","                          callbacks=[PlotLossesCallback(),es]);\n","    else:\n","        \n","        history = model.fit_generator(generator=train_generator,\n","                            validation_data = validation_generator,\n","                          steps_per_epoch=step_size_train,\n","                          epochs=maxEpochs);\n","\n","\n","\n","\n","\n","    # list all data in history\n","    print(history.history.keys())\n","    # summarize history for accuracy\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('Model Accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()\n","    # summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model Loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()\n","\n","\n","    ### Save Model\n","    tf.keras.models.save_model(\n","        model,\n","        modelName,\n","        overwrite=True,\n","        include_optimizer=True\n","    )\n","\n","    #### Save Label Names\n","    labels = (train_generator.class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    print(labels);\n","\n","    fid = open('label_' + selectedModel + '.sav','wb');\n","    pickle.dump(labels, fid);\n","    fid.close();\n","\n","\n","    print(\"Model successfully trained and saved.\");\n","\n","\n","\n","### Evaluate Trained Model\n","def testModel():\n","\n","    #from tensorflow.keras.preprocessing import image\n","    if selectedModel == \"vgg16\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.vgg16 import preprocess_input\n","        sourceModel = keras.applications.VGG16\n","    elif selectedModel == \"inceptionv3\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_v3 import preprocess_input\n","        sourceModel = keras.applications.InceptionV3\n","    elif selectedModel == \"inceptionv2\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"resnet50\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.resnet50 import preprocess_input\n","        sourceModel = keras.applications.ResNet50\n","    elif selectedModel == \"mobilenetv2\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","        sourceModel = keras.applications.MobileNetV2\n","    elif selectedModel == \"inceptionresnetv2\":\n","        imgsz = 299\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"mobilenet\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.mobilenet import preprocess_input\n","        sourceModel = keras.applications.MobileNet\n","    elif selectedModel == \"xception\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.xception import preprocess_input\n","        sourceModel = keras.applications.Xception\n","\n","\n","    \n","    modelName = \"model_\" + selectedModel;\n","\n","\n","    testmodel = tf.keras.models.load_model(\n","        modelName)\n","    #    custom_objects=None,\n","    #    compile=True\n","    #)\n","\n","    f = open(\"label_\" + selectedModel + \".sav\",'rb');labels = pickle.load(f);f.close();\n","    labels = list(labels.values());\n","\n","    X = [];\n","    y = [];\n","\n","    \n","    for label in labels:\n","\n","        fileList = []\n","        for ctrext in range(0,len(ext)):\n","            \n","            fileList.extend(glob.glob(dataPath[:-1] + \"test\" + \"/\" + label + \"/*\" + ext[ctrext]))\n","            \n","        \n","        \n","        for thisFile in fileList:\n","            \n","            ## CV IMAGE LOAD\n","            try:\n","              img = cv.imread(thisFile)\n","              img = cv.cvtColor(img,cv.COLOR_BGR2RGB);\n","            \n","              img = cv.resize(img,(imgsz,imgsz));\n","              \n","              img = preprocess_input(img);\n","            \n","            except:\n","              print(\"There was a problem processing this image:\")\n","              print(thisFile)\n","              print(\"Remove the image and try again.\")\n","              return\n","\n","            X.append(img);\n","            y.append(labels.index(label));\n","            \n","        \n","\n","    y_preds = testmodel.predict(np.array(X));\n","    y_pred = [];\n","    for y_preds_i in y_preds:\n","        y_pred.append(np.argmax(y_preds_i));\n","    #y_pred = testmodel.predict(X);\n","\n","    accuracy = sum(np.equal(y_pred,y)) / len(y) * 100\n","\n","    print()\n","    print(\"RANK 1 Accuracy Against Test Data: \" + \"{:.2f}\".format(accuracy) + \" %\");\n","\n","\n","    confmat = confusion_matrix(y, y_pred)\n","\n","    print()\n","    print('CONFUSION MATRIX:')\n","    print(confmat)\n","\n","    print(labels);\n","\n","    print();\n","    print(\"CLASSIFICATION REPORT:\")\n","    print(classification_report(y, y_pred))\n","\n","\n","\n","\n","\n","    ## SHOW OUTPUT BREAKDOWN\n","    print()\n","    print(\"OUTPUT DISTRIBUTION:\")\n","    outctr = 0;\n","    total = sum(sum(confmat));\n","    for col in confmat.T:\n","        \n","        totalcol = sum(col)\n","        \n","        print(labels[outctr] + \": \" + (\"%1.2f\") % ((totalcol / total) * 100) + \"%\")\n","        \n","        outctr = outctr + 1;\n","\n","\n","\n","def testOne():\n","    #from tensorflow.keras.preprocessing import image\n","    if selectedModel == \"vgg16\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.vgg16 import preprocess_input\n","        sourceModel = keras.applications.VGG16\n","    elif selectedModel == \"inceptionv3\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_v3 import preprocess_input\n","        sourceModel = keras.applications.InceptionV3\n","    elif selectedModel == \"inceptionv2\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"resnet50\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.resnet50 import preprocess_input\n","        sourceModel = keras.applications.ResNet50\n","    elif selectedModel == \"mobilenetv2\":\n","        imgsz = 224; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","        sourceModel = keras.applications.MobileNetV2\n","    elif selectedModel == \"inceptionresnetv2\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n","        sourceModel = keras.applications.InceptionResNetV2\n","    elif selectedModel == \"xception\":\n","        imgsz = 299; ## 224 resnet and vgg, 299 for inception\n","        from tensorflow.keras.applications.xception import preprocess_input\n","        sourceModel = keras.applications.Xception\n","        \n","        \n","\n","    modelName = \"model_\" + selectedModel;\n","\n","\n","    testmodel = tf.keras.models.load_model(\n","        modelName)\n","    #    custom_objects=None,\n","    #    compile=True\n","    #)\n","\n","    f = open(\"label_\" + selectedModel + \".sav\",'rb');labels = pickle.load(f);f.close();\n","    labels = list(labels.values());\n","\n","    X = [];\n","    y = [];\n","\n","\n","    idx = random.randint(0,len(labels)-1)\n","    label = labels[idx]\n","\n","    imgFiles = []\n","    for ctrext in range(0,len(ext)):\n","        imgFiles.extend(glob.glob(dataPath[:-1] + \"test\" + \"/\" + label + \"/*\" + ext[ctrext]))\n","\n","    idxFile = random.randint(0,len(imgFiles)-1)\n","\n","    filepath = imgFiles[idxFile]\n","    pos1 = filepath.find(\"/\")\n","    pos2 = filepath.find(\"/\",pos1+1)\n","    actualClass = filepath[pos1+1:pos2]\n","\n","    ## CV IMAGE LOAD\n","    img = cv.imread(filepath);\n","    img = cv.cvtColor(img,cv.COLOR_BGR2RGB);\n","\n","\n","    plt.title(\"Input Image\")\n","    plt.imshow(img)\n","    plt.show()\n","  \n","    img = cv.resize(img,(imgsz,imgsz));\n","    img = preprocess_input(img);\n","\n","    y_pred = testmodel.predict(np.array([img]));\n","    print(\"Image Classified as: \",labels[np.argmax(y_pred[0])])\n","    print(\"Actual Class:\",actualClass)\n","    print(\"Classification Score: \",max(y_pred[0]))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-tntAvGdZXT"},"source":["############# TRAINING PARAMETERS ##############\n","\n","selectedModel = \"vgg16\"; ## \"vgg16\" \"inceptionresnetv2\" \"inceptionv3\" \"resnet50\" \"mobilenet\" \"mobilenetv2\"\n","neurons = [4096,0.5,4096,0.5,512] ## Vgg 16: [4096,1024,256] , inceptionresnetv2 [], mobilenet neurons = [1024,256]\n","dataPath = 'traindatafolder/' ## Folder of Cropped Images\n","\n","ext = [\".jpg\",\".JPG\",\".jpeg\",\".JPEG\",\".png\",\".PNG\"]\n","#ext = [\".jpeg\"]\n","learningRate = 0.000005; ## VGG: 0.000001 ##inceptionresnetv2 0.000001\n","test_split_size=0.25\n","validation_split_size=0.25;\n","maxEpochs = 1000; \n","useAllSamples = False ## True to Consume All Traindata per Epoch (for feature crucial classification like defects)\n","batchSize = 8 # 128; \n","fixedStepSize = 32 ## If useAllSamples is False, get no. steps per epoch\n","enableEarlyStop = True;\n","estype = \"val_loss\"\n","patience = 25\n","layersToUnfreeze = 0\n","\n","## Data Augment Parameters\n","rotAngle = 0\n","flipHorizontal = False\n","flipVertical = False\n","\n","\n","import os\n","for root, dirs, files in os.walk(dataPath):\n","    break;\n","\n","numClasses = len(dirs);\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4KaQfSacvJK"},"source":["##### FUNCTION SEQUENCE #####"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaA_S-5ic3wz"},"source":["splitDataset()  ### Split the Dataset into Training+Validation and Testing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skMIU7Boc7i6"},"source":["trainModel()  ### Train the Deep Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNyhbyT6dB_a"},"source":["testModel()  ## Test with All of Test Dataset and Print Metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KGTKGLwP8kE"},"source":["testOne()  ## Test With One Random Image from Test Dataset"],"execution_count":null,"outputs":[]}]}